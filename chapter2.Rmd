# Assignment 2

**Eeva Vakkari**

<https://github.com/EevaVakkari/IODS-project>

## Introduction and overview
This week, I studied linear regression using a survey data set combined with exam results from a university statistics course. I made a simple linear model and validated it graphically.
First two code blocks contain the data wrangling part and, after them, the analysis part starts.


```{r}
date()
```
I performed the data wrangling as instructed:
```{r}
library(tidyverse) 
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
lrn14$attitude <- lrn14$Attitude / 10
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
lrn14$deep <- rowMeans(lrn14[, deep_questions])
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
lrn14$surf <- rowMeans(lrn14[, surface_questions])
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
lrn14$stra <- rowMeans(lrn14[, strategic_questions])
str(lrn14)
dim(lrn14)
```
At this point, the data set consists of 63 numerical and 1 character variables. All together 183 observations.
Now, let's focus on a subset of the data:
```{r}
library(dplyr)
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
analysis <- select(lrn14, one_of(keep_columns))
analysis <- filter_if(analysis, is.numeric, all_vars((.) != 0)) #removing all zeros
setwd("~/Polyembryony_R/IODS/IODS-project/data")
write.csv(analysis, "learning2014.csv", row.names = F)
a <- read.csv("learning2014.csv") #Checking that csv is OK.
str(a)
head(a)
```
Looking good. Continuing into analysis part of the assignment.
Setting the working directory and reading the csv into a data frame:
```{r}
setwd("~/Polyembryony_R/IODS/IODS-project/data")
learning2014 <- read.csv("learning2014.csv")
str(learning2014)
head(learning2014)
```
The data consists of learning approach survey results combined with student success in the exam. There are 7 variables and 166 observations.
```{r}
pairs(learning2014[-1])
library(GGally)
library(ggplot2)
p <- ggpairs(learning2014, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
```
Exam success, as represented by "Points", seems to correlate with attitude. Other plots do not suggest strong correlations between the variables. Let's study attitude, age and gender as explanatory variables for exam points.

```{r}
my_model1 <- lm(Points ~ Attitude + Age + gender, data = learning2014)
summary(my_model1)
```
When studied with two-sided Student's t-test, it seems that only attitude has statistically significant effect on exam points whereas age and gender do not explain the exam success. Attitude correlates positively with exam points: with better attitude, the exam points tend to be higher.
Making a new model with attitude as the only explanatory variable.
```{r}
my_model2 <- lm(Points ~ Attitude, data = learning2014)
summary(my_model2)
```
Also, the second model shows that attitude clearly has a statistically significant, positive correlation with exam points.
Removing age and gender from the model drops adjusted R-squared value by 0.0014, indicating a very minor (i.e. insignificant) drop in the power of the model.
Making diagnostic plots with the second model.

```{r}
plot(my_model2, which = c(1, 2, 5))
```
Linear regression model is based on four assumptions: 
1. There is a linear relationship between predictor(s) and outcome
2. The residuals are independent
3. The residuals are normally distributed
4. The residuals have equal variance
As demonstrated before, the attitude and exam points have linear relationship.
We can confidently assume that residuals are independent since the original survey is represent individual students at a single time point, i.e. autocorrelation is not a concern. This is seen as a flat line in the residuals vs. fitted values plot.
The Q-Q plot shows that the residuals are not completely normally distributed but quite close to it.
The residuals vs leverage plot shows that all data points are nowhere close to Cook's distance, i.e. don't have high leverage. So, there are no too influential single data points.

